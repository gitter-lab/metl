{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3776167c-2388-430e-9e49-418cd1ed2630",
   "metadata": {},
   "source": [
    "# Generate splits for an experimental dataset\n",
    "This notebook shows how to generate splits for an experimental dataset, using the avGFP dataset as an example.\n",
    "\n",
    "You can generate multiple types of splits.\n",
    "- A \"super test\" or withholding split. It's a simple random sample of variants meant to be completely held out until the final model training and evaluation.\n",
    "- Classic train, validation, and test splits based on percentages of the total dataset.\n",
    "- Reduced dataset sizes for evaluating performance as a function of training set size.\n",
    "- Extrapolation splits (mutation, position, score, and regime extrapolation) for testing the generalization performance of the models.\n",
    "\n",
    "\n",
    "This example generates a single replicate of each type of split, but it is recommended to use multiple replicates in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13a5a8b-bcc8-4263-9584-27c9b54a25a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T22:51:36.573559Z",
     "start_time": "2024-02-16T22:51:36.569490Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c82462e3-adb2-4387-b011-c162f2c5e3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# define the name of the project root directory\n",
    "project_root_dir_name = \"metl\"\n",
    "\n",
    "# find the project root by checking each parent directory\n",
    "current_dir = os.getcwd()\n",
    "while os.path.basename(current_dir) != project_root_dir_name and current_dir != os.path.dirname(current_dir):\n",
    "    current_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# change the current working directory to the project root directory\n",
    "if os.path.basename(current_dir) == project_root_dir_name:\n",
    "    os.chdir(current_dir)\n",
    "else:\n",
    "    print(\"project root directory not found\")\n",
    "    \n",
    "# add the project code folder to the system path so imports work\n",
    "module_path = os.path.abspath(\"code\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aceee92-8f31-4405-bcac-f06742d0c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import split_dataset as sd\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "063a9145-9832-4f43-9465-f0043a8dcb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger(\"METL\")\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a49ff16-9df3-445d-b6e1-1eeca8cbcf4d",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70a9703d-4955-453a-b53f-431cf4d0eba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = \"avgfp\"\n",
    "ds = utils.load_dataset(ds_name)\n",
    "\n",
    "# some additional info needed for extrapolation splits\n",
    "datasets = utils.load_dataset_metadata()\n",
    "seq_len = len(datasets[ds_name][\"wt_aa\"])\n",
    "wt_ofs = datasets[ds_name][\"wt_ofs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a60e6e-d07a-4285-841a-63c95b75e043",
   "metadata": {},
   "source": [
    "# Withhold a \"super test\" set\n",
    "\n",
    "I recommend having a completely held-out \"super test\" set. Don't use this set for development of the algorithm and don't look at evaluation results on this set until the very end, when you are ready to publish. Here we will create a super test set for avgfp and save it to the avgfp splits directory [data/avgfp/splits](../data/avgfp/splits).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18dd84e2-9671-4740-badc-260fd96d5bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:METL.split_dataset:saving supertest split to file data/dms_data/avgfp/splits/supertest_w1abc2f4e9a64_s0.1_r5958.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data/dms_data/avgfp/splits/supertest_w1abc2f4e9a64_s0.1_r5958.txt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir = \"data/dms_data/avgfp/splits/\"\n",
    "\n",
    "# use a fixed random seed for demonstration purposes\n",
    "# rseed = random.randint(1000, 9999)\n",
    "rseed = 5958\n",
    "\n",
    "supertest_idxs, supertest_fn = sd.supertest(ds, size=.1, rseed=rseed, out_dir=out_dir, overwrite=False)\n",
    "supertest_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7b6702-fbf8-4efa-a06c-65801ccf2059",
   "metadata": {},
   "source": [
    "# Standard train, validation, and test splits\n",
    "\n",
    "This will randomly sample train, validation, and test splits from the full dataset. You must specify the size of each set as a fraction of the total number of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b29caa1-e46a-412e-8664-e685979f0d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:METL.split_dataset:saving train-val-test split to directory data/dms_data/avgfp/splits/standard/standard_tr0.8_tu0.1_te0.1_w1abc2f4e9a64_r3597\n"
     ]
    }
   ],
   "source": [
    "out_dir = \"data/dms_data/avgfp/splits/standard\"\n",
    "\n",
    "# specify the super test set from above\n",
    "# this set will be withheld from this train test split\n",
    "withhold_fn = \"data/dms_data/avgfp/splits/supertest_w1abc2f4e9a64_s0.1_r5958.txt\"\n",
    "\n",
    "# specify 80% train, 10% validation, and 10% test sizes\n",
    "train_size = 0.8\n",
    "val_size = 0.1\n",
    "test_size = 0.1\n",
    "\n",
    "# multiple replicate splits\n",
    "replicates = 1\n",
    "\n",
    "# random seeds\n",
    "# rseeds = [random.randint(1000, 9999) for _ in range(replicates)]\n",
    "# for purposes of this demo, make the rseeds constant\n",
    "rseeds = [3597]\n",
    "\n",
    "for rseed in rseeds:    \n",
    "    split, out_dir_split = sd.train_val_test(ds, \n",
    "                                             train_size=train_size, \n",
    "                                             val_size=val_size, \n",
    "                                             test_size=test_size, \n",
    "                                             withhold=withhold_fn, \n",
    "                                             out_dir=out_dir, \n",
    "                                             rseed=rseed, \n",
    "                                             overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2140b6ae-c5d5-4924-be52-44a5832bd6f9",
   "metadata": {},
   "source": [
    "# Resampled dataset sizes\n",
    "\n",
    "This splits enable you to evaluate performance as a function of train size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c88aff00-918b-400e-8a3b-d0018b3e6554",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:METL.split_dataset:saving resampled split to directory data/dms_data/avgfp/splits/resampled/resampled_ds10_val0.2_te0.1_w1abc2f4e9a64_s1_r8099\n",
      "INFO:METL.split_dataset:saving resampled split to directory data/dms_data/avgfp/splits/resampled/resampled_ds20_val0.2_te0.1_w1abc2f4e9a64_s1_r8099\n",
      "INFO:METL.split_dataset:saving resampled split to directory data/dms_data/avgfp/splits/resampled/resampled_ds40_val0.2_te0.1_w1abc2f4e9a64_s1_r8099\n",
      "INFO:METL.split_dataset:saving resampled split to directory data/dms_data/avgfp/splits/resampled/resampled_ds80_val0.2_te0.1_w1abc2f4e9a64_s1_r8099\n",
      "INFO:METL.split_dataset:saving resampled split to directory data/dms_data/avgfp/splits/resampled/resampled_ds160_val0.2_te0.1_w1abc2f4e9a64_s1_r8099\n",
      "INFO:METL.split_dataset:saving resampled split to directory data/dms_data/avgfp/splits/resampled/resampled_ds320_val0.2_te0.1_w1abc2f4e9a64_s1_r8099\n",
      "INFO:METL.split_dataset:saving resampled split to directory data/dms_data/avgfp/splits/resampled/resampled_ds640_val0.2_te0.1_w1abc2f4e9a64_s1_r8099\n",
      "INFO:METL.split_dataset:saving resampled split to directory data/dms_data/avgfp/splits/resampled/resampled_ds1280_val0.2_te0.1_w1abc2f4e9a64_s1_r8099\n",
      "INFO:METL.split_dataset:saving resampled split to directory data/dms_data/avgfp/splits/resampled/resampled_ds2560_val0.2_te0.1_w1abc2f4e9a64_s1_r8099\n",
      "INFO:METL.split_dataset:saving resampled split to directory data/dms_data/avgfp/splits/resampled/resampled_ds5120_val0.2_te0.1_w1abc2f4e9a64_s1_r8099\n",
      "INFO:METL.split_dataset:saving resampled split to directory data/dms_data/avgfp/splits/resampled/resampled_ds10240_val0.2_te0.1_w1abc2f4e9a64_s1_r8099\n",
      "INFO:METL.split_dataset:saving resampled split to directory data/dms_data/avgfp/splits/resampled/resampled_ds20480_val0.2_te0.1_w1abc2f4e9a64_s1_r8099\n"
     ]
    }
   ],
   "source": [
    "out_dir = \"data/dms_data/avgfp/splits/resampled\"\n",
    "withhold_fn = \"data/dms_data/avgfp/splits/supertest_w1abc2f4e9a64_s0.1_r5958.txt\"\n",
    "\n",
    "# specify the dataset sizes and number of replicates per dataset size\n",
    "dataset_sizes = [10, 20, 40, 80, 160, 320, 640, 1280, 2560, 5120, 10240, 20480]\n",
    "# just one replicate for each dataset size for this example\n",
    "replicates = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "# use multiple replicates in practice\n",
    "# replicates = [101, 23, 11, 11, 11, 11, 7, 7, 5, 5, 3, 3]\n",
    "\n",
    "# rseed = random.randint(1000, 9999)\n",
    "rseed = 8099\n",
    "\n",
    "# the test set is sampled from the full dataset\n",
    "test_fraction = 0.1\n",
    "\n",
    "# the validation set is sampled from the reduced dataset size\n",
    "# the train set will be 1 minus the validation fraction\n",
    "# so in this case, the train set will be 80%, and the validation set 20%\n",
    "val_fraction = 0.2\n",
    "\n",
    "# create the suite of resampled dataset size splits\n",
    "for ds_size, reps in zip(dataset_sizes, replicates):\n",
    "    splits, reduced_split_dir = sd.resampled_dataset_size(full_dataset_size=ds.shape[0], \n",
    "                                                          test_fraction=test_fraction, \n",
    "                                                          dataset_size=ds_size,\n",
    "                                                          val_fraction=val_fraction,\n",
    "                                                          num_replicates=reps, \n",
    "                                                          withhold=withhold_fn, \n",
    "                                                          rseed=rseed, \n",
    "                                                          out_dir=out_dir,\n",
    "                                                          overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f45b81-3abf-4ad9-9509-97e3c742f019",
   "metadata": {},
   "source": [
    "# Position extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "858ea4f4-7fac-4472-a61a-e27235255751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:METL.split_dataset:num_train_positions: 190, num_test_positions: 47\n",
      "INFO:METL.split_dataset:train pool size: 25528, test pool size: 655, overlap pool size: 25531\n",
      "INFO:METL.split_dataset:num_train: 22975, num_val: 2553, num_test: 655\n",
      "INFO:METL.split_dataset:saving train-val-test split to directory data/dms_data/avgfp/splits/position/position_tr-pos0.8_tu0.1_r6822\n"
     ]
    }
   ],
   "source": [
    "out_dir = \"data/dms_data/avgfp/splits/position\"\n",
    "\n",
    "# 80% of positions are designated train pool, 20% are desinated test pool\n",
    "train_pos_size = 0.8\n",
    "\n",
    "# the training pool is split into 90% training set and 10% validation set \n",
    "val_size = 0.1\n",
    "\n",
    "# if the dataset is very large or you want to standardize the dataset size at\n",
    "# which you perform position extrapolation, you can optionally specify that\n",
    "# dataset size here\n",
    "resample_dataset_size = None\n",
    "\n",
    "replicates = 1\n",
    "# rseeds = [random.randint(1000, 9999) for _ in range(replicates)]\n",
    "rseeds = [6822]\n",
    "\n",
    "for rseed in rseeds:    \n",
    "    split, out_dir_split, additional_info = sd.position_split(ds, \n",
    "                                                              seq_len, \n",
    "                                                              wt_ofs, \n",
    "                                                              train_pos_size, \n",
    "                                                              val_size,\n",
    "                                                              resample_dataset_size=resample_dataset_size,\n",
    "                                                              out_dir=out_dir, \n",
    "                                                              rseed=rseed, \n",
    "                                                              overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fa093a-a43e-4a67-8c5e-3da1e78b8f22",
   "metadata": {},
   "source": [
    "# Mutation extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd30a32c-aed8-417c-b8fd-8903b954ec51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:METL.split_dataset:number of unique mutations in ds: 1810\n",
      "INFO:METL.split_dataset:num_train_mutations: 1448, num_test_mutations: 362\n",
      "INFO:METL.split_dataset:train pool size: 24078, test pool size: 791, overlap pool size: 26845\n",
      "INFO:METL.split_dataset:num_train: 21670, num_val: 2408, num_test: 791\n",
      "INFO:METL.split_dataset:saving train-val-test split to directory data/dms_data/avgfp/splits/mutation/mutation_tr-muts0.8_tu0.1_r4419\n"
     ]
    }
   ],
   "source": [
    "out_dir = \"data/dms_data/avgfp/splits/mutation\"\n",
    "\n",
    "resample_dataset_size = None\n",
    "\n",
    "# 80% of mutations are designated train pool, 20% are desinated test pool\n",
    "train_muts_size = 0.8\n",
    "\n",
    "# the training pool is split into 90% training set and 10% validation set \n",
    "val_size = 0.1\n",
    "\n",
    "replicates = 1\n",
    "# rseeds = [random.randint(1000, 9999) for _ in range(replicates)]\n",
    "rseeds = [4419]\n",
    "\n",
    "for rseed in rseeds:    \n",
    "    split, out_dir_split, additional_info = sd.mutation_split(ds, \n",
    "                                                              train_muts_size,\n",
    "                                                              val_size, \n",
    "                                                              out_dir=out_dir, \n",
    "                                                              rseed=rseed, \n",
    "                                                              resample_dataset_size=resample_dataset_size,\n",
    "                                                              overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e3a8c-3a65-42b1-97de-6c818a35401a",
   "metadata": {},
   "source": [
    "# Score extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cd05918-b386-4644-8651-02d87b2c7a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:METL.split_dataset:train pool size: 46683, test pool size: 5031\n",
      "INFO:METL.split_dataset:num_train: 42014, num_val: 4669, num_test: 5031\n",
      "INFO:METL.split_dataset:saving train-val-test split to directory data/dms_data/avgfp/splits/score/score_thresh0_tu0.1_r5265\n"
     ]
    }
   ],
   "source": [
    "out_dir = \"data/dms_data/avgfp/splits/score\"\n",
    "\n",
    "resample_dataset_size = None\n",
    "\n",
    "# set the wild-type score for this dataset\n",
    "wt_score = 0\n",
    "score_name = \"score\"\n",
    "\n",
    "# training pool is split into 90% train and 10% validation sets \n",
    "val_size = 0.1\n",
    "\n",
    "replicates = 1\n",
    "# rseeds = [random.randint(1000, 9999) for _ in range(replicates)]\n",
    "rseeds = [5265]\n",
    "\n",
    "for rseed in rseeds:    \n",
    "    split, out_dir_split = sd.score_extrapolation_split(ds, \n",
    "                                                     score_name=score_name, \n",
    "                                                     wt_score=wt_score, \n",
    "                                                     val_size=val_size,\n",
    "                                                     resample_dataset_size=resample_dataset_size,\n",
    "                                                     out_dir=out_dir,\n",
    "                                                     rseed=rseed, \n",
    "                                                     overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae4a900-250c-49c7-aab6-4e5cb390ded2",
   "metadata": {},
   "source": [
    "# Regime extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c65d536-c2f6-412b-b15a-6ed4353b40cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:METL.split_dataset:train pool size: 1084, test pool size: 50630, discard pool size: 0\n",
      "INFO:METL.split_dataset:num_train: 867, num_val: 217, num_test: 5063\n",
      "INFO:METL.split_dataset:saving train-val-test split to directory data/dms_data/avgfp/splits/regime/regime_tr-reg1_te-reg2-3-4-5-6-7-8-9-10-11-12-13-14-15_tr0.8_tu0.2_te0.1_r9067\n"
     ]
    }
   ],
   "source": [
    "out_dir = \"data/dms_data/avgfp/splits/regime\"\n",
    "\n",
    "train_regimes = 1\n",
    "test_regimes = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "\n",
    "# for the train pool (all single mutants)\n",
    "# use 80% as the training set and 20% as the validation set\n",
    "train_size = 0.8\n",
    "val_size = 0.2\n",
    "\n",
    "# for the test pool (all 2+ mutants), don't use all for the test set\n",
    "# to help lessen risk of overfitting to full test set during development\n",
    "# the test set will be just 10% of all available 2+ mutants\n",
    "test_size = 0.1\n",
    "\n",
    "\n",
    "replicates = 1\n",
    "# rseeds = [random.randint(1000, 9999) for _ in range(replicates)]\n",
    "rseeds = [8903]\n",
    "\n",
    "for _ in range(replicates):    \n",
    "    rseed = random.randint(1000,9999)\n",
    "    split, out_dir_split, additional_info = sd.regime_split(ds, \n",
    "                                                            train_regimes=train_regimes, \n",
    "                                                            test_regimes=test_regimes, \n",
    "                                                            train_size=train_size, \n",
    "                                                            val_size=val_size, \n",
    "                                                            test_size=test_size,\n",
    "                                                            rseed=rseed, \n",
    "                                                            out_dir=out_dir, \n",
    "                                                            overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cfbfb5-220a-47be-9ee5-d0de9e7d72a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
