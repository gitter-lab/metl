{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e30ea18e-6b5a-47d4-b7a4-1330804b5602",
      "metadata": {
        "id": "e30ea18e-6b5a-47d4-b7a4-1330804b5602"
      },
      "source": [
        "# Finetune on experimental data\n",
        "This notebook demonstrates how to finetune METL models on experimental data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "vZx7K4mpi4w1",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZx7K4mpi4w1",
        "outputId": "08606a43-e6f3-4967-e09c-a05bda6e2fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'metl'...\n",
            "remote: Enumerating objects: 416, done.\u001b[K\n",
            "remote: Counting objects: 100% (416/416), done.\u001b[K\n",
            "remote: Compressing objects: 100% (280/280), done.\u001b[K\n",
            "remote: Total 416 (delta 166), reused 330 (delta 98), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (416/416), 18.08 MiB | 14.06 MiB/s, done.\n",
            "Resolving deltas: 100% (166/166), done.\n",
            "/content/metl\n"
          ]
        }
      ],
      "source": [
        "# @title Cloning metl\n",
        "!git clone https://github.com/gitter-lab/metl.git\n",
        "%cd metl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "vl7ugAoEjNFQ",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl7ugAoEjNFQ",
        "outputId": "37a27f98-3c5a-4351-93b0-2a950970e7fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-28 22:01:31--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.191.158, 104.16.32.241, 2606:4700::6810:20f1, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.191.158|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 148981743 (142M) [application/octet-stream]\n",
            "Saving to: ‘./miniconda.sh’\n",
            "\n",
            "./miniconda.sh      100%[===================>] 142.08M  87.1MB/s    in 1.6s    \n",
            "\n",
            "2024-08-28 22:01:32 (87.1 MB/s) - ‘./miniconda.sh’ saved [148981743/148981743]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "\n",
            "Installing base environment...\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Channels:\n",
            " - conda-forge\n",
            " - defaults\n",
            " - pytorch\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "done\n",
            "Installing pip dependencies: ...working... done\n"
          ]
        }
      ],
      "source": [
        "# @title Setting up conda to download notebook dependencies (this takes a while)\n",
        "# @markdown This step may take 10-20 minutes.\n",
        "\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ./miniconda.sh\n",
        "!chmod +x miniconda.sh\n",
        "!bash ./miniconda.sh -b -u -p /usr/local\n",
        "!conda env update -q -n base -f ./environment.yml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "432eebaf-00b8-42bf-b927-fd651e6ab94d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-16T22:51:36.573559Z",
          "start_time": "2024-02-16T22:51:36.569490Z"
        },
        "id": "432eebaf-00b8-42bf-b927-fd651e6ab94d",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c566507e-1012-4415-82ba-7498950e0b6c",
      "metadata": {
        "id": "c566507e-1012-4415-82ba-7498950e0b6c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append('/usr/local/lib/python3.9/site-packages')\n",
        "# define the name of the project root directory\n",
        "project_root_dir_name = \"metl\"\n",
        "\n",
        "# find the project root by checking each parent directory\n",
        "current_dir = os.getcwd()\n",
        "while os.path.basename(current_dir) != project_root_dir_name and current_dir != os.path.dirname(current_dir):\n",
        "    current_dir = os.path.dirname(current_dir)\n",
        "\n",
        "# change the current working directory to the project root directory\n",
        "if os.path.basename(current_dir) == project_root_dir_name:\n",
        "    os.chdir(current_dir)\n",
        "else:\n",
        "    print(\"project root directory not found\")\n",
        "\n",
        "# add the project code folder to the system path so imports work\n",
        "module_path = os.path.abspath(\"code\")\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19876208-66f9-46b5-8f50-8e798fa815a4",
      "metadata": {
        "id": "19876208-66f9-46b5-8f50-8e798fa815a4"
      },
      "source": [
        "# Acquire an experimental dataset\n",
        "\n",
        "For demonstration purposes, this repository contains the [avGFP dataset](https://github.com/gitter-lab/metl/tree/main/data/dms_data/avgfp) from [Sarkisyan et al. (2016)](https://doi.org/10.1038/nature17995).\n",
        "See the [metl-pub](https://github.com/gitter-lab/metl-pub) repository to access the other experimental datasets we used in our preprint.\n",
        "See the README in the [dms_data](https://github.com/gitter-lab/metl/tree/main/data/dms_data/) directory for information about how to use your own experimental dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6abf8b1-aa2d-4055-9184-d962ba0d4582",
      "metadata": {
        "id": "d6abf8b1-aa2d-4055-9184-d962ba0d4582"
      },
      "source": [
        "# Acquire a pretrained model\n",
        "Pretrained METL models are available in the [metl-pretrained](https://github.com/gitter-lab/metl-pretrained) repository. You can use one of those, or you can pretrain your own METL model (see [pretraining.ipynb](https://github.com/gitter-lab/metl/blob/main/notebooks/pretraining.ipynb)).\n",
        "\n",
        "For demonstration purposes, we include a pretrained avGFP METL-Local model from the [metl-pretrained](https://github.com/gitter-lab/metl-pretrained) repository in the [pretrained_models](https://github.com/gitter-lab/metl/tree/main/pretrained_models) directory. This model is `METL-L-2M-3D-GFP` (UUID: `Hr4GNHws`).\n",
        "It is the avGFP METL-Local source model we used for the analysis in our preprint.\n",
        "\n",
        "We will show how to finetune this model using the [experimental avGFP dataset](https://github.com/gitter-lab/metl/tree/main/data/dms_data/avgfp)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23a30235-357a-4326-a4ff-77ab26eb5d7f",
      "metadata": {
        "id": "23a30235-357a-4326-a4ff-77ab26eb5d7f"
      },
      "source": [
        "# Training arguments\n",
        "\n",
        "The script for finetuning on experimental data is [train_target_model.py](https://github.com/gitter-lab/metl/blob/main/code/train_target_model.py). This script has a number of arguments you can view by uncommenting and running the below cell. There are additional arguments related to architecture that won't show up if you run the command, but you can view them in [models.py](https://github.com/gitter-lab/metl/tree/main/code/models.py) in the `TransferModel` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bca8aeea-3dc3-47eb-915c-d80132be8fef",
      "metadata": {
        "id": "bca8aeea-3dc3-47eb-915c-d80132be8fef"
      },
      "outputs": [],
      "source": [
        "# !python code/train_target_model.py -h"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ec8c31b-2da2-4ba7-9f4e-39e30dce8056",
      "metadata": {
        "id": "7ec8c31b-2da2-4ba7-9f4e-39e30dce8056"
      },
      "source": [
        "We set up finetuning arguments for this example in [finetune_avgfp_local.txt](https://github.com/gitter-lab/metl/tree/main/args/pretrain_avgfp_local.txt) in the [args](https://github.com/gitter-lab/metl/tree/main/args) directory. This argument file can be used directly with [train_target_model.py](https://github.com/gitter-lab/metl/blob/main/code/train_target_model.py) by calling the command `!python code/train_target_model.py @args/finetune_avgfp_local.txt` (we do this in the next section).\n",
        "\n",
        "Uncomment and run the cell below to view the contents of the argument file. The sections below will walk through and explain the key arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a06a897f-877d-4e41-9bee-4d3eabeead7d",
      "metadata": {
        "id": "a06a897f-877d-4e41-9bee-4d3eabeead7d"
      },
      "outputs": [],
      "source": [
        "# with open(\"args/finetune_avgfp_local.txt\", \"r\") as file:\n",
        "#     contents = file.read()\n",
        "#     print(contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2610124-fa2c-4709-98fc-bae51b258338",
      "metadata": {
        "id": "c2610124-fa2c-4709-98fc-bae51b258338"
      },
      "source": [
        "## Dataset arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f56ee90-90be-41fa-bc99-c13f94e14976",
      "metadata": {
        "id": "9f56ee90-90be-41fa-bc99-c13f94e14976"
      },
      "source": [
        "\n",
        "Specify the dataset name and the train/val/test split. The dataset must be defined in [datasets.yml](https://github.com/gitter-lab/metl/tree/main/data/dms_data/datasets.yml). For demonstration purposes, we are using one of the reduced dataset size splits with a dataset size of 160 (train size of 128).\n",
        "```\n",
        "--ds_name\n",
        "avgfp\n",
        "--split_dir\n",
        "data/dms_data/avgfp/splits/resampled/resampled_ds160_val0.2_te0.1_w1abc2f4e9a64_s1_r8099/resampled_ds160_val0.2_te0.1_w1abc2f4e9a64_s1_r8099_rep_0\n",
        "```\n",
        "\n",
        "Specify the names of the train, validation, and test set files in the split directory. Using \"auto\" for the test_name will select the super test set (\"stest.txt\") if it exists in the split directory, otherwise it will use the standard test set (\"test.txt\").\n",
        "\n",
        "```\n",
        "--train_name\n",
        "train\n",
        "--val_name\n",
        "val\n",
        "--test_name\n",
        "test\n",
        "```\n",
        "\n",
        "The name of the target column in the dataset dataframe. The model will be finetuned to predict the score in this column.\n",
        "\n",
        "```\n",
        "--target_names\n",
        "score\n",
        "```\n",
        "\n",
        "The METL-Local model we are finetuning uses 3D structure-based relative position embeddings, so we need to specify the PDB filename. This PDB file is in the [data/pdb_files](https://github.com/gitter-lab/metl/tree/main/data/pdb_files) directory, which the script checks by default, so there is no need to specify the full path. You can also just specify \"auto\" to use the PDB file defined for this dataset in [datasets.yml](https://github.com/gitter-lab/metl/tree/main/data/dms_data/datasets.yml).\n",
        "\n",
        "```\n",
        "--pdb_fn\n",
        "1gfl_cm.pdb\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "890cea13-feae-4e54-bf0f-dcbe97f4409f",
      "metadata": {
        "id": "890cea13-feae-4e54-bf0f-dcbe97f4409f"
      },
      "source": [
        "## Network architecture arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72ee9762-cae7-4e21-8435-f6dd49781b8c",
      "metadata": {
        "id": "72ee9762-cae7-4e21-8435-f6dd49781b8c"
      },
      "source": [
        "For finetuning, we implemented a special model `transfer_model` that handles pretrained checkpoints with top nets.\n",
        "```\n",
        "--model_name\n",
        "transfer_model\n",
        "```\n",
        "\n",
        "The pretrained checkpoint can be a PyTorch checkpoint (.pt file) downloaded from the [metl-pretrained](https://github.com/gitter-lab/metl-pretrained) repository or a PyTorch Lightning checkpoint (.ckpt file) obtained from pretraining a model with this repository.\n",
        "```\n",
        "--pretrained_ckpt_path\n",
        "pretrained_models/Hr4GNHws.pt\n",
        "```\n",
        "\n",
        "The backbone cutoff determines where to cutoff the pretrained model and place the new prediction head. For METL-Local models, we recommend backbone cutoff -1, and for METL-Global models we recommend backbone cutoff -2.\n",
        "\n",
        "```\n",
        "--backbone_cutoff\n",
        "-1\n",
        "```\n",
        "\n",
        "The remaining arguments determine the encoding, which should be set to `int_seqs`, whether to use dropout after the backbone cutoff, and the architecture of the new top net. You can leave these values as-is to match what we did for the preprint.\n",
        "\n",
        "```\n",
        "--encoding\n",
        "int_seqs\n",
        "--dropout_after_backbone\n",
        "--dropout_after_backbone_rate\n",
        "0.5\n",
        "--top_net_type\n",
        "linear\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d94c112-9770-4a5f-93e0-acf4d9acae16",
      "metadata": {
        "id": "8d94c112-9770-4a5f-93e0-acf4d9acae16"
      },
      "source": [
        "## Finetuning strategy arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bb96cb6-7815-4efa-9b6f-305df9bb3050",
      "metadata": {
        "id": "7bb96cb6-7815-4efa-9b6f-305df9bb3050"
      },
      "source": [
        "We implemented a dual-phase finetuning strategy. During the first phase, the backbone weights are frozen and only the top net is trained. During the second phase, all the network weights are unfrozen and trained at a reduced learning rate.\n",
        "\n",
        "The unfreeze_backbone_at_epoch argument determines the training epoch at which to unfreeze the backbone. We train the models for 500 epochs, so the backbone is unfrozen halfway through at epoch 250.\n",
        "\n",
        "```\n",
        "--finetuning\n",
        "--finetuning_strategy\n",
        "backbone\n",
        "--unfreeze_backbone_at_epoch\n",
        "250\n",
        "--backbone_always_align_lr\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f51d4584-a0ce-45c3-8fb7-8c34d3a984c3",
      "metadata": {
        "id": "f51d4584-a0ce-45c3-8fb7-8c34d3a984c3"
      },
      "source": [
        "## Optimization arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d90d10e8-21f3-4b9e-8134-99cb053bef13",
      "metadata": {
        "id": "d90d10e8-21f3-4b9e-8134-99cb053bef13"
      },
      "source": [
        "Basic optimizer arguments include the batch size, learning rate, and maximum number of epochs to train for. Unless early stopping is enabled, the model will train for the given number of epochs.\n",
        "\n",
        "```\n",
        "--optimizer\n",
        "adamw\n",
        "--weight_decay\n",
        "0.1\n",
        "--batch_size\n",
        "128\n",
        "--learning_rate\n",
        "0.001\n",
        "--max_epochs\n",
        "500\n",
        "--gradient_clip_val\n",
        "0.5\n",
        "```\n",
        "\n",
        "The learning rate scheduler we used for finetuning is a dual phase learning rate schedule that matches the dual phase finetuning strategy. Each phase has a linear learning rate warmup for 1% of the total steps in that phase. There is also a cosine decay for the learning rate for each phase. The phase 2 learning rate is 10% of the phase 1 learning rate.\n",
        "\n",
        "```\n",
        "--lr_scheduler\n",
        "dual_phase_warmup_constant_cosine_decay\n",
        "--warmup_steps\n",
        ".01\n",
        "--phase2_lr_ratio\n",
        "0.1\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16327f53-7beb-412e-a925-12884e66d70b",
      "metadata": {
        "id": "16327f53-7beb-412e-a925-12884e66d70b"
      },
      "source": [
        "## Logging arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "132db93c-85e6-4658-a31e-9b103df34cb7",
      "metadata": {
        "id": "132db93c-85e6-4658-a31e-9b103df34cb7"
      },
      "source": [
        "We have built in functionality for tracking model training with Weights & Biases. If you have a Weights and Biases account, set the environment variable `WANDB_API_KEY` to your API key and set the flag `--use_wandb` instead of `--no_use_wandb` below.\n",
        "\n",
        "```\n",
        "--no_use_wandb\n",
        "--wandb_project\n",
        "metl-target\n",
        "--wandb_online\n",
        "--experiment\n",
        "default\n",
        "```\n",
        "\n",
        "The below argument determines where to place the log directory locally.\n",
        "```\n",
        "--log_dir_base\n",
        "output/training_logs\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a2fda3-6dfa-46d5-ad3d-3055eda0b29a",
      "metadata": {
        "id": "53a2fda3-6dfa-46d5-ad3d-3055eda0b29a"
      },
      "source": [
        "# Running training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d3d8d23-9d54-4888-842d-4fc8fd843b40",
      "metadata": {
        "id": "8d3d8d23-9d54-4888-842d-4fc8fd843b40"
      },
      "source": [
        "All the arguments described above are contained in [finetune_avgfp_local.txt](https://github.com/gitter-lab/metl/tree/main/args/pretrain_avgfp_local.txt), which can be fed directly into [train_target_model.py](https://github.com/gitter-lab/metl/blob/main/code/train_target_model.py).\n",
        "\n",
        "PyTorch Lightning has a built-in progress bar that is convenient for seeing training progress, but it does not display correctly in Jupyter when calling the script with `!python`. We are going to disable the progress bar for by setting the flag `--enable_progress_bar false`. Instead, we implemented a simple print statement to track training progress, which we will enable with the flag `--enable_simple_progress_messages`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "977b4d8d-4662-4e03-955c-dc4a8ae7c1dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "977b4d8d-4662-4e03-955c-dc4a8ae7c1dc",
        "outputId": "a487d3f2-97fd-47ea-d07b-9c0cd21c9fb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed not specified, using: 522644021\n",
            "Global seed set to 522644021\n",
            "Created model UUID: fmngE6sB\n",
            "Created log directory: output/training_logs/fmngE6sB\n",
            "Final UUID: fmngE6sB\n",
            "Final log directory: output/training_logs/fmngE6sB\n",
            "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Loading `train_dataloader` to estimate number of stepping batches.\n",
            "/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n",
            "Number of training steps is 50\n",
            "Number of warmup steps is 0.5\n",
            "Second warmup phase starts at step 25\n",
            "total_steps 50\n",
            "phase1_total_steps 25\n",
            "phase2_total_steps 25\n",
            "┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
            "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName                  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m  In sizes\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m Out sizes\u001b[0m\u001b[1;35m \u001b[0m┃\n",
            "┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
            "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model                  │ TransferModel      │  2.4 M │\u001b[37m \u001b[0m\u001b[37m[128, 237]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m  [128, 1]\u001b[0m\u001b[37m \u001b[0m│\n",
            "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ model.model            │ SequentialWithArgs │  2.4 M │\u001b[37m \u001b[0m\u001b[37m[128, 237]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m  [128, 1]\u001b[0m\u001b[37m \u001b[0m│\n",
            "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ model.model.backbone   │ SequentialWithArgs │  2.4 M │\u001b[37m \u001b[0m\u001b[37m[128, 237]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m[128, 256]\u001b[0m\u001b[37m \u001b[0m│\n",
            "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ model.model.dropout    │ Dropout            │      0 │\u001b[37m \u001b[0m\u001b[37m[128, 256]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m[128, 256]\u001b[0m\u001b[37m \u001b[0m│\n",
            "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ model.model.flatten    │ Flatten            │      0 │\u001b[37m \u001b[0m\u001b[37m[128, 256]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m[128, 256]\u001b[0m\u001b[37m \u001b[0m│\n",
            "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ model.model.prediction │ Linear             │    257 │\u001b[37m \u001b[0m\u001b[37m[128, 256]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m  [128, 1]\u001b[0m\u001b[37m \u001b[0m│\n",
            "│\u001b[2m \u001b[0m\u001b[2m6\u001b[0m\u001b[2m \u001b[0m│ test_pearson           │ PearsonCorrCoef    │      0 │\u001b[37m \u001b[0m\u001b[37m         ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m         ?\u001b[0m\u001b[37m \u001b[0m│\n",
            "│\u001b[2m \u001b[0m\u001b[2m7\u001b[0m\u001b[2m \u001b[0m│ test_spearman          │ SpearmanCorrCoef   │      0 │\u001b[37m \u001b[0m\u001b[37m         ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m         ?\u001b[0m\u001b[37m \u001b[0m│\n",
            "└───┴────────────────────────┴────────────────────┴────────┴────────────┴────────────┘\n",
            "\u001b[1mTrainable params\u001b[0m: 257                                                                               \n",
            "\u001b[1mNon-trainable params\u001b[0m: 2.4 M                                                                         \n",
            "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                 \n",
            "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                           \n",
            "Starting sanity check...\n",
            "Sanity check complete.\n",
            "Starting training...\n",
            "Epoch     0: Train Loss =   2.322, Val Loss =   2.024\n",
            "Epoch     1: Train Loss =   2.348, Val Loss =   1.977\n",
            "Epoch     2: Train Loss =   2.255, Val Loss =   1.931\n",
            "Epoch     3: Train Loss =   2.265, Val Loss =   1.888\n",
            "Epoch     4: Train Loss =   2.179, Val Loss =   1.846\n",
            "Epoch     5: Train Loss =   2.138, Val Loss =   1.807\n",
            "Epoch     6: Train Loss =   2.080, Val Loss =   1.770\n",
            "Epoch     7: Train Loss =   2.037, Val Loss =   1.735\n",
            "Epoch     8: Train Loss =   1.982, Val Loss =   1.703\n",
            "Epoch     9: Train Loss =   1.948, Val Loss =   1.674\n",
            "Epoch    10: Train Loss =   1.962, Val Loss =   1.648\n",
            "Epoch    11: Train Loss =   1.894, Val Loss =   1.624\n",
            "Epoch    12: Train Loss =   1.903, Val Loss =   1.603\n",
            "Epoch    13: Train Loss =   1.889, Val Loss =   1.585\n",
            "Epoch    14: Train Loss =   1.822, Val Loss =   1.570\n",
            "Epoch    15: Train Loss =   1.838, Val Loss =   1.556\n",
            "Epoch    16: Train Loss =   1.811, Val Loss =   1.546\n",
            "Epoch    17: Train Loss =   1.808, Val Loss =   1.537\n",
            "Epoch    18: Train Loss =   1.803, Val Loss =   1.530\n",
            "Epoch    19: Train Loss =   1.754, Val Loss =   1.525\n",
            "Epoch    20: Train Loss =   1.788, Val Loss =   1.521\n",
            "Epoch    21: Train Loss =   1.779, Val Loss =   1.519\n",
            "Epoch    22: Train Loss =   1.771, Val Loss =   1.518\n",
            "Epoch    23: Train Loss =   1.790, Val Loss =   1.517\n",
            "Epoch    24: Train Loss =   1.803, Val Loss =   1.517\n",
            "Epoch    25: Train Loss =   1.824, Val Loss =   1.517\n",
            "Epoch    26: Train Loss =   1.773, Val Loss =   1.486\n",
            "Epoch    27: Train Loss =   1.741, Val Loss =   1.455\n",
            "Epoch    28: Train Loss =   1.674, Val Loss =   1.425\n",
            "Epoch    29: Train Loss =   1.671, Val Loss =   1.394\n",
            "Epoch    30: Train Loss =   1.592, Val Loss =   1.365\n",
            "Epoch    31: Train Loss =   1.603, Val Loss =   1.335\n",
            "Epoch    32: Train Loss =   1.581, Val Loss =   1.307\n",
            "Epoch    33: Train Loss =   1.526, Val Loss =   1.279\n",
            "Epoch    34: Train Loss =   1.489, Val Loss =   1.253\n",
            "Epoch    35: Train Loss =   1.445, Val Loss =   1.228\n",
            "Epoch    36: Train Loss =   1.375, Val Loss =   1.203\n",
            "Epoch    37: Train Loss =   1.394, Val Loss =   1.181\n",
            "Epoch    38: Train Loss =   1.337, Val Loss =   1.160\n",
            "Epoch    39: Train Loss =   1.358, Val Loss =   1.142\n",
            "Epoch    40: Train Loss =   1.326, Val Loss =   1.126\n",
            "Epoch    41: Train Loss =   1.259, Val Loss =   1.111\n",
            "Epoch    42: Train Loss =   1.200, Val Loss =   1.099\n",
            "Epoch    43: Train Loss =   1.180, Val Loss =   1.090\n",
            "Epoch    44: Train Loss =   1.148, Val Loss =   1.082\n",
            "Epoch    45: Train Loss =   1.126, Val Loss =   1.076\n",
            "Epoch    46: Train Loss =   1.182, Val Loss =   1.072\n",
            "Epoch    47: Train Loss =   1.177, Val Loss =   1.070\n",
            "Epoch    48: Train Loss =   1.168, Val Loss =   1.069\n",
            "Epoch    49: Train Loss =   1.091, Val Loss =   1.069\n",
            "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "Restoring states from the checkpoint path at output/training_logs/fmngE6sB/checkpoints/epoch=49-step=50.ckpt\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Loaded model weights from checkpoint at output/training_logs/fmngE6sB/checkpoints/epoch=49-step=50.ckpt\n",
            "/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Starting testing...\n",
            "Testing complete.\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.2109477519989014    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      test_pearson       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6558916568756104    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m      test_spearman      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6332594752311707    \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "Restoring states from the checkpoint path at output/training_logs/fmngE6sB/checkpoints/epoch=49-step=50.ckpt\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Loaded model weights from checkpoint at output/training_logs/fmngE6sB/checkpoints/epoch=49-step=50.ckpt\n",
            "Starting prediction...\n",
            "Prediction complete.\n",
            "saving a scatter plot for set: train (128 variants)\n",
            "saving a scatter plot for set: val (32 variants)\n",
            "saving a scatter plot for set: test (4655 variants)\n",
            "            mse  pearsonr        r2  spearmanr\n",
            "set                                           \n",
            "train  1.286097  0.734186 -0.102364   0.693757\n",
            "val    1.069018  0.737532  0.008699   0.725690\n",
            "test   1.210948  0.655892 -0.087824   0.633260\n"
          ]
        }
      ],
      "source": [
        "!python code/train_target_model.py @args/finetune_avgfp_local.txt --enable_progress_bar false --enable_simple_progress_messages --max_epochs 50 --unfreeze_backbone_at_epoch 25"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f33fc407-6ab1-45e3-8e6a-9b717dca7f00",
      "metadata": {
        "id": "f33fc407-6ab1-45e3-8e6a-9b717dca7f00"
      },
      "source": [
        "# Additional recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39c8e0e5-8bb5-4200-ab45-e559b0f20896",
      "metadata": {
        "id": "39c8e0e5-8bb5-4200-ab45-e559b0f20896",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Model selection\n",
        "\n",
        "Selecting the model from the epoch with the lowest validation set loss can help prevent overfitting. It requires having a big enough validation set that provides an accurate estimate of performance.\n",
        "\n",
        "We enabled model selection if the validation set size was ≥ 32 for METL-Local and ≥ 128 for METL-Global. We found the optimization was more stable for METL-Local than METL-Global, thus smaller validation sets were still reliable.\n",
        "\n",
        "Enable model selection by setting argument `--ckpt_monitor val`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b18f773b-8209-4993-b3f0-994b0ab2b133",
      "metadata": {
        "id": "b18f773b-8209-4993-b3f0-994b0ab2b133"
      },
      "source": [
        "## Backbone cutoff for METL-Global\n",
        "Finetuning METL-Global is largely the same as METL-Local, except we recommend using a different threshold for model selection (see above), as well as a different backbone cutoff.\n",
        "\n",
        "For METL-Local, we set `--backbone_cutoff -1`, which attaches the new prediction head immediately after the final fully connected layer.\n",
        "\n",
        "For METL-Global, we recommend setting `--backbone_cutoff -2`, which attaches the new prediction head immediately after the global pooling layer. We found this resulted in better finetuning performance for METL-Global."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a591eb8-3d5e-437f-9189-3c0834f7f447",
      "metadata": {
        "id": "2a591eb8-3d5e-437f-9189-3c0834f7f447"
      },
      "source": [
        "# Running inference using finetuned model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af85ff8f-1a30-4ba2-bf3b-967a773e0e80",
      "metadata": {
        "id": "af85ff8f-1a30-4ba2-bf3b-967a773e0e80"
      },
      "source": [
        "The PyTorch Lightning framework supports inference, but while we put together a working example, we recommend converting the PyTorch Lightning checkpoint to pure PyTorch and using the [metl-pretrained](https://github.com/gitter-lab/metl-pretrained) package to run inference in pure PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1acca5d1-1bca-4c3f-b9d3-56525cf11186",
      "metadata": {
        "id": "1acca5d1-1bca-4c3f-b9d3-56525cf11186"
      },
      "source": [
        "## Convert to PyTorch\n",
        "Lightning checkpoints are compatible with pure pytorch, but they may contain additional items that are not needed for inference. This script loads the checkpoint and saves a smaller checkpoint with just the model weights and hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "63d8ce0a-5534-406f-90b6-6c155cb6ea9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63d8ce0a-5534-406f-90b6-6c155cb6ea9c",
        "outputId": "3406c304-902c-425d-ebe5-65d03c3b480c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing checkpoint: output/training_logs/fmngE6sB/checkpoints/epoch=49-step=50.ckpt\n",
            "Saving converted checkpoint to: output/training_logs/fmngE6sB/checkpoints/fmngE6sB.pt\n"
          ]
        }
      ],
      "source": [
        "# the Lightning checkpoint from the finetuning we performed above\n",
        "fine_tuning_dir_name = os.listdir('output/training_logs')[0]\n",
        "\n",
        "ckpt_fn = f\"output/training_logs/{fine_tuning_dir_name}/checkpoints/epoch=49-step=50.ckpt\"\n",
        "\n",
        "# run the conversion script\n",
        "!python code/convert_ckpt.py --ckpt_path $ckpt_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98b562aa-663a-4b0d-a719-e85555cf875d",
      "metadata": {
        "id": "98b562aa-663a-4b0d-a719-e85555cf875d"
      },
      "source": [
        "## Load checkpoint with metl-pretrained package\n",
        "Using the Hugging Face wrapper, we can load the metl library and use it to load our newly trained model checkpoint and run inference with it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ff35ce69-97ed-4a5a-b082-f197aae1addc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341,
          "referenced_widgets": [
            "b7b47f570c8c43b6bf2230e6a44d3e09",
            "219fdb01577845ea8fe0ad54a77cf65d",
            "275bb85ac0104926a7988da85947b332",
            "f7f2291a716346888c03cf0481b3b4b7",
            "55be7aa5f252407bbe8e00f1c182fb22",
            "ac4e32e574354ec095f92678a0313f4e",
            "5c3b1f7e1e75469da8d453d63c762aad",
            "a2f6a37975d54b418fde8afdeb86ffa0",
            "6f0c2bfb83ab494fa67af09ad82f1a19",
            "1dea0603d40b4d4f84193876183ebfbc",
            "cdf78bd9b62d4d5c9809f9ff99cd296b",
            "adf1bab3a2cc4ceb94031be73340031e",
            "a9e9d6e3751f42b0857e3c6736af3fc7",
            "98ffe8af93d5480e94c00ba5f09db454",
            "cc76bf4678fd49148f5f25236daa43d2",
            "908beed2fd40426db19081750bfac4fb",
            "2b5138e0f130467d9af35736eb8bce41",
            "865015002a294027951beda6cbc1a07c",
            "5642d3dea048402abf2cad21c25a4c01",
            "7e920825842744eeb4d00631b5ffc08a",
            "4d0d620efc564efa8e0e069c59a14460",
            "79b93dcc01304185a65877e0a51e861d",
            "ef9b97e9f9434dc79b2201bde062a0c4",
            "e6df8ef3f9ca4e17a76a093c753a5b47",
            "f78d7b0a73974cbea0d992824c9a795f",
            "16a9352d655043e682c1cb20f8214479",
            "f12897838468411c94e8126a56890057",
            "5d4f099cd3624ae9adc500aa93a80ae0",
            "c4250b0106404bc78368f17819f51fde",
            "dacad6e28f7e4b369dbf7f03c88fa00e",
            "ae47fbb36d6a4f4ba3394a2c85fb599e",
            "95c96e9e3f2e4ad48cf08e55a4341d1e",
            "ace8a8608099458e84cfb991ad462631"
          ]
        },
        "id": "ff35ce69-97ed-4a5a-b082-f197aae1addc",
        "outputId": "e549e68a-df63-42e2-f687-c6923882db07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/269 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7b47f570c8c43b6bf2230e6a44d3e09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "huggingface_wrapper.py:   0%|          | 0.00/95.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "adf1bab3a2cc4ceb94031be73340031e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/gitter-lab/METL:\n",
            "- huggingface_wrapper.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/176 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef9b97e9f9434dc79b2201bde062a0c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at gitter-lab/METL were not used when initializing METLModel: ['model.bias', 'model.weight']\n",
            "- This IS expected if you are initializing METLModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing METLModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "metl = AutoModel.from_pretrained('gitter-lab/METL', trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "jmVkPSI5G7bE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmVkPSI5G7bE",
        "outputId": "c3ead9fe-3a30-4627-c713-36899160ab11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized PDB bucket matrices in: 0.000\n",
            "Initialized PDB bucket matrices in: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/huggingface/modules/transformers_modules/gitter-lab/METL/934ed6dbc8561ad4a1f005d1df9276c0db3f4562/huggingface_wrapper.py:2045: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(ckpt_fn, map_location=\"cpu\")\n"
          ]
        }
      ],
      "source": [
        "checkpoint_path = f\"output/training_logs/{fine_tuning_dir_name}/checkpoints/{fine_tuning_dir_name}.pt\"\n",
        "metl.get_from_checkpoint(checkpoint_path)\n",
        "model = metl.model\n",
        "data_encoder = metl.encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7efa0346-d84b-42ca-ab4b-ed4ae3120933",
      "metadata": {
        "id": "7efa0346-d84b-42ca-ab4b-ed4ae3120933"
      },
      "source": [
        "## Run inference with pure PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "VdU6Xja_H0L_",
      "metadata": {
        "id": "VdU6Xja_H0L_"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "import torch\n",
        "\n",
        "def load_dataset_metadata(metadata_fn: str = \"data/dms_data/datasets.yml\"):\n",
        "    with open(metadata_fn, \"r\") as stream:\n",
        "        try:\n",
        "            datasets = yaml.safe_load(stream)\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(exc)\n",
        "    return datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "33202a3e-5e35-4b55-8738-3b58ad04796e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33202a3e-5e35-4b55-8738-3b58ad04796e",
        "outputId": "4cb62b77-779b-4a47-cbc1-bced1240cb87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3088],\n",
            "        [-0.4627],\n",
            "        [-0.5127]])\n"
          ]
        }
      ],
      "source": [
        "# load the GFP wild-type sequence and the PDB file (needed for 3D RPE)\n",
        "datasets = load_dataset_metadata()\n",
        "wt = datasets[\"avgfp\"][\"wt_aa\"]\n",
        "pdb_fn = datasets[\"avgfp\"][\"pdb_fn\"]\n",
        "\n",
        "# some example GFP variants to compute the scores for\n",
        "variants = [\"E3K,G102S\",\n",
        "            \"T36P,S203T,K207R\",\n",
        "            \"V10A,D19G,F25S,E113V\"]\n",
        "\n",
        "encoded_variants = data_encoder.encode_variants(wt, variants)\n",
        "\n",
        "# set model to eval mode\n",
        "model.eval()\n",
        "\n",
        "# no need to compute gradients for inference\n",
        "with torch.no_grad():\n",
        "    # note we are specifying the pdb_fn because this model uses 3D RPE\n",
        "    predictions = model(torch.tensor(encoded_variants), pdb_fn=pdb_fn)\n",
        "\n",
        "print(predictions)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b7b47f570c8c43b6bf2230e6a44d3e09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_219fdb01577845ea8fe0ad54a77cf65d",
              "IPY_MODEL_275bb85ac0104926a7988da85947b332",
              "IPY_MODEL_f7f2291a716346888c03cf0481b3b4b7"
            ],
            "layout": "IPY_MODEL_55be7aa5f252407bbe8e00f1c182fb22"
          }
        },
        "219fdb01577845ea8fe0ad54a77cf65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac4e32e574354ec095f92678a0313f4e",
            "placeholder": "​",
            "style": "IPY_MODEL_5c3b1f7e1e75469da8d453d63c762aad",
            "value": "config.json: 100%"
          }
        },
        "275bb85ac0104926a7988da85947b332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2f6a37975d54b418fde8afdeb86ffa0",
            "max": 269,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f0c2bfb83ab494fa67af09ad82f1a19",
            "value": 269
          }
        },
        "f7f2291a716346888c03cf0481b3b4b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dea0603d40b4d4f84193876183ebfbc",
            "placeholder": "​",
            "style": "IPY_MODEL_cdf78bd9b62d4d5c9809f9ff99cd296b",
            "value": " 269/269 [00:00&lt;00:00, 16.9kB/s]"
          }
        },
        "55be7aa5f252407bbe8e00f1c182fb22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac4e32e574354ec095f92678a0313f4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c3b1f7e1e75469da8d453d63c762aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2f6a37975d54b418fde8afdeb86ffa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f0c2bfb83ab494fa67af09ad82f1a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1dea0603d40b4d4f84193876183ebfbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdf78bd9b62d4d5c9809f9ff99cd296b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adf1bab3a2cc4ceb94031be73340031e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9e9d6e3751f42b0857e3c6736af3fc7",
              "IPY_MODEL_98ffe8af93d5480e94c00ba5f09db454",
              "IPY_MODEL_cc76bf4678fd49148f5f25236daa43d2"
            ],
            "layout": "IPY_MODEL_908beed2fd40426db19081750bfac4fb"
          }
        },
        "a9e9d6e3751f42b0857e3c6736af3fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b5138e0f130467d9af35736eb8bce41",
            "placeholder": "​",
            "style": "IPY_MODEL_865015002a294027951beda6cbc1a07c",
            "value": "huggingface_wrapper.py: 100%"
          }
        },
        "98ffe8af93d5480e94c00ba5f09db454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5642d3dea048402abf2cad21c25a4c01",
            "max": 95901,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e920825842744eeb4d00631b5ffc08a",
            "value": 95901
          }
        },
        "cc76bf4678fd49148f5f25236daa43d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d0d620efc564efa8e0e069c59a14460",
            "placeholder": "​",
            "style": "IPY_MODEL_79b93dcc01304185a65877e0a51e861d",
            "value": " 95.9k/95.9k [00:00&lt;00:00, 1.28MB/s]"
          }
        },
        "908beed2fd40426db19081750bfac4fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b5138e0f130467d9af35736eb8bce41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "865015002a294027951beda6cbc1a07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5642d3dea048402abf2cad21c25a4c01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e920825842744eeb4d00631b5ffc08a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d0d620efc564efa8e0e069c59a14460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79b93dcc01304185a65877e0a51e861d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef9b97e9f9434dc79b2201bde062a0c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6df8ef3f9ca4e17a76a093c753a5b47",
              "IPY_MODEL_f78d7b0a73974cbea0d992824c9a795f",
              "IPY_MODEL_16a9352d655043e682c1cb20f8214479"
            ],
            "layout": "IPY_MODEL_f12897838468411c94e8126a56890057"
          }
        },
        "e6df8ef3f9ca4e17a76a093c753a5b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d4f099cd3624ae9adc500aa93a80ae0",
            "placeholder": "​",
            "style": "IPY_MODEL_c4250b0106404bc78368f17819f51fde",
            "value": "model.safetensors: 100%"
          }
        },
        "f78d7b0a73974cbea0d992824c9a795f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dacad6e28f7e4b369dbf7f03c88fa00e",
            "max": 176,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae47fbb36d6a4f4ba3394a2c85fb599e",
            "value": 176
          }
        },
        "16a9352d655043e682c1cb20f8214479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95c96e9e3f2e4ad48cf08e55a4341d1e",
            "placeholder": "​",
            "style": "IPY_MODEL_ace8a8608099458e84cfb991ad462631",
            "value": " 176/176 [00:00&lt;00:00, 9.53kB/s]"
          }
        },
        "f12897838468411c94e8126a56890057": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d4f099cd3624ae9adc500aa93a80ae0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4250b0106404bc78368f17819f51fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dacad6e28f7e4b369dbf7f03c88fa00e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae47fbb36d6a4f4ba3394a2c85fb599e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95c96e9e3f2e4ad48cf08e55a4341d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ace8a8608099458e84cfb991ad462631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}